{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Rangely Station Air Quality Scraper\n",
    "\n",
    "This script scrapes air quality and meteorological data from the Rangely Station monitoring site\n",
    "on the Colowhite River Air Quality website. It retrieves data on meteorology, ozone (O3), \n",
    "particulate matter (PM2.5), and nitrogen dioxide (NO2), then prints the data and saves it \n",
    "to a Parquet file with a timestamped filename.\n",
    "\n",
    "Dependencies:\n",
    "- pandas\n",
    "- selenium\n",
    "- webdriver-manager\n",
    "- datetime\n",
    "- time\n",
    "\n",
    "Usage:\n",
    "    python rangely_scraper.py\n",
    "\n",
    "Ensure that all dependencies are installed. The script runs in headless mode using Chrome WebDriver.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "\n",
    "def scrape_rangely_station():\n",
    "    \"\"\"\n",
    "    Scrapes air quality and meteorological data from the Rangely Station monitoring site.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Configures Selenium WebDriver with headless Chrome options.\n",
    "    2. Navigates to the Rangely Station monitoring page.\n",
    "    3. Extracts data for meteorology, ozone (O3), particulate matter (PM2.5), and nitrogen dioxide (NO2).\n",
    "    4. Compiles the extracted data into a dictionary with a timestamp.\n",
    "    5. Returns the data dictionary and the current datetime.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - dict: A dictionary containing the timestamp and nested dictionaries for each data category.\n",
    "            - datetime: The current datetime when the data was scraped.\n",
    "\n",
    "    Example:\n",
    "        data, timestamp = scrape_rangely_station()\n",
    "    \"\"\"\n",
    "    # Set up Chrome options\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument('--headless')  # Run Chrome in headless mode\n",
    "    chrome_options.add_argument('--no-sandbox')  # Bypass OS security model\n",
    "    chrome_options.add_argument('--disable-dev-shm-usage')  # Overcome limited resource problems\n",
    "\n",
    "    try:\n",
    "        # Initialize the WebDriver using ChromeDriverManager\n",
    "        service = Service(ChromeDriverManager().install())\n",
    "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "        # Set window size to ensure all elements are visible\n",
    "        driver.set_window_size(1920, 1080)\n",
    "\n",
    "        # Navigate to the Rangely Station monitoring page\n",
    "        url = 'https://www.colowhiteriverairquality.net/monitoring-sites/rangely-station.html'\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait for the page to load completely\n",
    "        wait = WebDriverWait(driver, 60)\n",
    "\n",
    "        # Initialize data dictionary with the current timestamp\n",
    "        current_datetime = datetime.now()\n",
    "        data = {\n",
    "            'timestamp': current_datetime.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'meteorology': {},\n",
    "            'ozone': {},\n",
    "            'pm25': {},\n",
    "            'no2': {}\n",
    "        }\n",
    "\n",
    "        # Print page title for debugging purposes\n",
    "        print(f\"Page title: {driver.title}\")\n",
    "\n",
    "        try:\n",
    "            # Scrape Meteorological Data\n",
    "            meteorology_section = wait.until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//h5[contains(text(), 'Current Meteorology')]\"))\n",
    "            )\n",
    "            meteorology_table = meteorology_section.find_element(By.XPATH, \"following-sibling::table\")\n",
    "\n",
    "            rows = meteorology_table.find_elements(By.TAG_NAME, \"tr\")\n",
    "            for row in rows:\n",
    "                cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "                if len(cols) == 2:\n",
    "                    key = cols[0].text.strip()\n",
    "                    value = cols[1].text.strip()\n",
    "                    if key:  # Only add if key is not empty\n",
    "                        data['meteorology'][key] = value\n",
    "\n",
    "            # Scrape Ozone (O3) Data\n",
    "            ozone_section = wait.until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//h5[contains(text(), 'Ozone')]\"))\n",
    "            )\n",
    "            ozone_table = ozone_section.find_element(By.XPATH, \"following-sibling::table\")\n",
    "\n",
    "            rows = ozone_table.find_elements(By.TAG_NAME, \"tr\")\n",
    "            for row in rows:\n",
    "                cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "                if len(cols) == 2:\n",
    "                    key = cols[0].text.strip()\n",
    "                    value = cols[1].text.strip()\n",
    "                    if key:\n",
    "                        data['ozone'][key] = value\n",
    "\n",
    "            # Scrape Particulate Matter (PM2.5) Data\n",
    "            pm25_section = wait.until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//h5[contains(text(), 'Particulate Matter')]\"))\n",
    "            )\n",
    "            pm25_table = pm25_section.find_element(By.XPATH, \"following-sibling::table\")\n",
    "\n",
    "            rows = pm25_table.find_elements(By.TAG_NAME, \"tr\")\n",
    "            for row in rows:\n",
    "                cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "                if len(cols) == 2:\n",
    "                    key = cols[0].text.strip()\n",
    "                    value = cols[1].text.strip()\n",
    "                    if key:\n",
    "                        data['pm25'][key] = value\n",
    "\n",
    "            # Scrape Nitrogen Dioxide (NO2) Data\n",
    "            no2_section = wait.until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//h5[contains(text(), 'Nitrogen Dioxide')]\"))\n",
    "            )\n",
    "            no2_table = no2_section.find_element(By.XPATH, \"following-sibling::table\")\n",
    "\n",
    "            rows = no2_table.find_elements(By.TAG_NAME, \"tr\")\n",
    "            for row in rows:\n",
    "                cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "                if len(cols) == 2:\n",
    "                    key = cols[0].text.strip()\n",
    "                    value = cols[1].text.strip()\n",
    "                    if key:\n",
    "                        data['no2'][key] = value\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while scraping data: {e}\")\n",
    "\n",
    "        return data, current_datetime\n",
    "\n",
    "    finally:\n",
    "        # Ensure the WebDriver is closed properly\n",
    "        if 'driver' in locals():\n",
    "            driver.quit()\n",
    "\n",
    "\n",
    "def print_data(data):\n",
    "    \"\"\"\n",
    "    Prints the scraped air quality and meteorological data in a readable format.\n",
    "\n",
    "    This function displays the timestamp, meteorological data, ozone (O3), particulate matter (PM2.5),\n",
    "    and nitrogen dioxide (NO2) data.\n",
    "\n",
    "    Args:\n",
    "        data (dict): The data dictionary containing timestamp and various air quality measurements.\n",
    "\n",
    "    Example:\n",
    "        print_data(data)\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        print(\"No data to display.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n=== Rangely Station Air Quality Data ===\")\n",
    "    print(f\"Timestamp: {data['timestamp']}\\n\")\n",
    "\n",
    "    print(\"Meteorological Data:\")\n",
    "    for key, value in data['meteorology'].items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print()\n",
    "\n",
    "    print(\"Ozone (O3):\")\n",
    "    for key, value in data['ozone'].items():\n",
    "        print(f\"{key}\\t{value}\")\n",
    "    print()\n",
    "\n",
    "    print(\"Particulate Matter (PM2.5):\")\n",
    "    for key, value in data['pm25'].items():\n",
    "        print(f\"{key}\\t{value}\")\n",
    "    print()\n",
    "\n",
    "    print(\"Nitrogen Dioxide (NO2):\")\n",
    "    for key, value in data['no2'].items():\n",
    "        print(f\"{key}\\t{value}\")\n",
    "\n",
    "\n",
    "def save_data_to_parquet(data, timestamp):\n",
    "    \"\"\"\n",
    "    Saves the scraped data to a Parquet file with a timestamped filename.\n",
    "\n",
    "    This function combines all data into a single dictionary, converts it to a pandas DataFrame,\n",
    "    and saves it as a compressed Parquet file using the 'pyarrow' engine.\n",
    "\n",
    "    Args:\n",
    "        data (dict): The data dictionary containing timestamp and various air quality measurements.\n",
    "        timestamp (datetime): The datetime object representing when the data was scraped.\n",
    "\n",
    "    Example:\n",
    "        save_data_to_parquet(data, current_datetime)\n",
    "    \"\"\"\n",
    "    # Combine all data into a single dictionary\n",
    "    combined_data = {\n",
    "        'timestamp': data['timestamp'],\n",
    "        **data['meteorology'],\n",
    "        **data['ozone'],\n",
    "        **data['pm25'],\n",
    "        **data['no2']\n",
    "    }\n",
    "\n",
    "    # Create a DataFrame from the combined data\n",
    "    df = pd.DataFrame([combined_data])\n",
    "\n",
    "    # Format the datetime for filename (e.g., '2024-10-23_153000')\n",
    "    formatted_timestamp = timestamp.strftime('%Y-%m-%d_%H%M%S')\n",
    "\n",
    "    # Create the filename with the formatted timestamp\n",
    "    filename = f\"rangely_{formatted_timestamp}.parquet\"\n",
    "\n",
    "    # Save the DataFrame to the Parquet file with the dynamic filename\n",
    "    df.to_parquet(\n",
    "        filename,\n",
    "        engine='pyarrow',\n",
    "        compression='gzip',\n",
    "        coerce_timestamps='ms',\n",
    "        allow_truncated_timestamps=True\n",
    "    )\n",
    "\n",
    "    print(f\"\\nAll data has been saved to '{filename}'\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Scrape data from the Rangely Station website\n",
    "    data, current_datetime = scrape_rangely_station()\n",
    "\n",
    "    # Print the scraped data to the console\n",
    "    print_data(data)\n",
    "\n",
    "    # Save the scraped data to a Parquet file\n",
    "    save_data_to_parquet(data, current_datetime)"
   ],
   "id": "977b87c25148cda2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
